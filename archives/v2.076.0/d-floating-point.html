
<!DOCTYPE html>
<html lang="en-US">
<!--
    Copyright (c) 1999-2017 by the D Language Foundation
    All Rights Reserved.
    https://dlang.org/foundation.html
  -->
<head>
<meta charset="utf-8">
<meta name="keywords" content="D programming language">
<meta name="description" content="D Programming Language">
<title>Real Close to the Machine: Floating Point in D - D Programming Language</title>

<link rel="stylesheet" href="css/codemirror.css">
<link rel="stylesheet" href="css/style.css">
<link rel="stylesheet" href="css/print.css" media="print">
<link rel="shortcut icon" href="favicon.ico">
<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=0.1, maximum-scale=10.0">

</head>
<body id='Real Close to the Machine: Floating Point in D' class='doc'>
<script type="text/javascript">document.body.className += ' have-javascript'</script>
<div id="top"><div class="helper"><div class="helper expand-container">    <div class="logo"><a href="."><img id="logo" alt="D Logo" src="images/dlogo.svg"></a></div>
    <a href="menu.html" title="Menu" class="hamburger expand-toggle"><span>Menu</span></a>
    
<div id="cssmenu"><ul>    <li><a href='https://tour.dlang.org'><span>Learn</span></a></li>
    <li class='expand-container'><a class='expand-toggle' href='documentation.html'><span>Documentation</span></a>
      
<ul class='expand-content'>    <li><a href='spec/spec.html'>Language Reference</a></li>
    <li><a href='phobos/index.html'>Library Reference</a></li>
    <li><a href='dmd.html'>Command-line Reference</a></li>
    <li class="menu-divider"><a href='comparison.html'>Feature Overview</a></li>
    <li><a href='articles.html'>Articles</a></li>
 </ul></li>
    <li><a href='download.html'><span>Downloads</span></a></li>
    <li><a href='https://code.dlang.org'><span>Packages</span></a></li>
    <li class='expand-container'><a class='expand-toggle' href='community.html'><span>Community</span></a>
      
<ul class='expand-content'>    <li><a href='https://dlang.org/blog'>Blog</a></li>
    <li><a href='orgs-using-d.html'>Orgs using D</a></li>
    <li><a href='https://twitter.com/search?q=%23dlang'>Twitter</a></li>
    <li class="menu-divider"><a href='https://forum.dlang.org'>Forums</a></li>
    <li><a href='irc://irc.freenode.net/d'>IRC</a></li>
    <li><a href='https://wiki.dlang.org'>Wiki</a></li>
    <li class="menu-divider"><a href='https://github.com/dlang'>GitHub</a></li>
    <li><a href='bugstats.html'>Issues</a></li>
    <li><a href='https://wiki.dlang.org/Get_involved'>Get involved</a></li>
    <li class="menu-divider"><a href='foundation.html'>Foundation</a></li>
    <li><a href='donate.html'>Donate</a></li>
 </ul></li>
    <li class='expand-container'><a class='expand-toggle' href='resources.html'><span>Resources</span></a>
      
<ul class='expand-content'>    <li><a href='https://wiki.dlang.org/Books'>Books</a></li>
    <li><a href='https://wiki.dlang.org/Tutorials'>Tutorials</a></li>
    <li class="menu-divider"><a href='https://wiki.dlang.org/Development_tools'>Tools</a></li>
    <li><a href='https://wiki.dlang.org/Editors'>Editors</a></li>
    <li><a href='https://wiki.dlang.org/IDEs'>IDEs</a></li>
    <li><a href='http://rainers.github.io/visuald/visuald/StartPage.html'>Visual D</a></li>
    <li class="menu-divider"><a href='acknowledgements.html'>Acknowledgments</a></li>
    <li><a href='dstyle.html'>D Style</a></li>
    <li><a href='glossary.html'>Glossary</a></li>
    <li><a href='sitemap.html'>Sitemap</a></li>
 </ul></li>
</ul></div>
    <div class="search-container expand-container">        <a href="search.html" class="expand-toggle" title="Search"><span>Search</span></a>
        
    <div id="search-box">        <form method="get" action="https://google.com/search">
            <input type="hidden" id="domains" name="domains" value="dlang.org">
            <input type="hidden" id="sourceid" name="sourceid" value="google-search">
            <span id="search-query"><input id="q" name="q" placeholder="Search"></span><span id="search-dropdown"><span class="helper">                <select id="sitesearch" name="sitesearch" size="1">
                    <option value="dlang.org">Entire Site</option>
                    <option  value="dlang.org/spec">Language</option>
                    <option  value="dlang.org/phobos">Library</option>
                    <option  value="forum.dlang.org">Forums</option>
                    
                </select>
            </span></span><span id="search-submit"><button type="submit"><i class="fa fa-search"></i><span>go</span></button></span>
        </form>
    </div>
    </div>
</div></div></div>

<div class="container">    
<div class="subnav-helper"></div> <div class="subnav">    
    <div class="head">        <h2>Articles</h2>
        <p class="Articles, articles.html, overview">            <a href="articles.html">overview</a></p>
    </div>
    <ul><li><a href='        faq.html'>FAQ</a></li><li><a href='        const-faq.html'>const(FAQ)</a></li><li><a href='        d-floating-point.html'>Floating Point</a></li><li><a href='        warnings.html'>Warnings</a></li><li><a href='        rationale.html'>Rationale</a></li><li><a href='        builtin.html'>Builtin Rationale</a></li><li><a href='        ctod.html'>C to D</a></li><li><a href='        cpptod.html'>C++ to D</a></li><li><a href='        pretod.html'>C Preprocessor vs D</a></li><li><a href='        code_coverage.html'>Code coverage analysis</a></li><li><a href='        exception-safe.html'>Exception Safety</a></li><li><a href='        hijack.html'>Hijacking</a></li><li><a href='        intro-to-datetime.html'>Introduction to std.datetime</a></li><li><a href='        lazy-evaluation.html'>Lazy Evaluation</a></li><li><a href='        migrate-to-shared.html'>Migrating to Shared</a></li><li><a href='        mixin.html'>Mixins</a></li><li><a href='        regular-expression.html'>Regular Expressions</a></li><li><a href='        safed.html'>SafeD</a></li><li><a href='        templates-revisited.html'>Templates Revisited</a></li><li><a href='        ctarguments.html'>Compile-time Argument Lists</a></li><li><a href='        variadic-function-templates.html'>Variadic Templates</a></li><li><a href='        d-array-article.html'>D Slices
    </a></li></ul>
</div>
    <div class="hyphenate" id="content">        
<div id="tools"><div >	<div class="tip smallprint">		<a href="https://issues.dlang.org/enter_bug.cgi?bug_file_loc=http%3A%2F%2Fdlang.org/&amp;bug_severity=enhancement&amp;component=dlang.org&amp;op_sys=All&amp;priority=P3&amp;product=D&amp;rep_platform=All&amp;short_desc=%5BReal Close to the Machine: Floating Point in D%5D&amp;version=D2">Report a bug</a>
		<div >			If you spot a problem with this page, click here to create a Bugzilla issue.
		</div>
	</div>
	<div class="tip smallprint">		<a href="https://github.com/dlang/dlang.org/edit/master/d-floating-point.dd">Improve this page</a>
		<div >			Quickly fork, edit online, and submit a pull request for this page.
			Requires a signed-in GitHub account. This works well for small changes.
			If you'd like to make larger changes you may want to consider using
			a local clone.
		</div>
	</div>
</div></div>
        <h1>Real Close to the Machine: Floating Point in D</h1>
        
        


<h2>Introduction</h2>

<p><i>by Don Clugston</i></p>

<p>Computers were originally conceived as devices for performing mathematics. The earliest computers spent most of their time solving equations. Although the engineering and scientific community now forms only a miniscule part of the computing world, there is a fantastic legacy from those former times: almost all computers now feature superb hardware for performing mathematical calculations accurately and extremely quickly. Sadly, most programming languages make it difficult for programmers to take full advantage of this hardware. An even bigger problem is the lack of documentation; even for many mathematical programmers, aspects of floating-point arithmetic remain shrouded in mystery.
</p>

<p>As a systems programming language, the D programming language attempts to remove all barriers between the programmer and the compiler, and between the programmer and the machine. This philosophy is particularly evident in support for floating-point arithmetic. A personal anecdote may illustrate the importance of having an accurate understanding of the hardware.
</p>

<p>My first floating-point nightmare occurred in a C++ program which hung once in every hundred runs or so. I eventually traced the problem to a while loop which occasionally failed to terminate. The essence of the code is shown in Listing 1.
</p>

<pre class="d_code notranslate"><span class="d_keyword">double</span> q[8];
...
<span class="d_keyword">int</span> x = 0;
<span class="d_keyword">while</span> (x &lt; 8)
{
    <span class="d_keyword">if</span> (q[x] &gt;= 0) <span class="d_keyword">return</span> <span class="d_keyword">true</span>;
    <span class="d_keyword">if</span> (q[x] &lt; 0) ++x;
}
<span class="d_keyword">return</span> <span class="d_keyword">false</span>;
</pre>

<p>Initially, I was completely baffled as to how this harmless-looking loop could fail. But eventually, I discovered that q had not been initialized properly; q[7] contained random garbage. Occasionally, that garbage had every bit set, which mean that q[7] was a Not-a-Number (NaN), a special code which indicates that the value of the variable is nonsense. NaNs were not mentioned in the compiler's documentation - the only information I could find about them was in Intel's assembly instruction set documentation! Any comparison involving a NaN is false, so q[7] was neither &gt;= 0, nor &lt; 0, killing my program. Until that unwelcome discovery, I'd been unaware that NaNs even existed. I had lived in a fool's paradise, mistakenly believing that every floating point number was either positive, negative, or zero.
</p>

<p>My experience would have been quite different in D. The "strange" features of floating point have a higher visibility in the language, improving the education of numerical programmers.
Uninitialized floating point numbers are initialized to NaN by the compiler, so the problematic loop would fail every time, not intermittently.
Numerical programmers in D will generally execute their programs with the 'invalid' floating point exception enabled. Under those circumstances, as soon as the program accessed the uninitialized variable, a hardware exception would occur, summoning the debugger.
Easy access to the "strange" features of floating point results in better educated programmers, reduced confusion, faster debugging, better testing, and hopefully, more reliable and correct numerical programs.
This article will provide a brief overview of the support for floating point in the D programming language.
</p>

<h2>Demystifying Floating-Point</h2>

<p>D guarantees that all built-in floating-point types conform to IEEE 754 arithmetic, making behaviour entirely predictable (note that this is <i>not</i> the same as producing identical results on all platforms). IEEE 754-2008 is the latest revision of the IEEE 754 Standard for Floating-Point Arithmetic. D is progressing towards full compliance with 754-2008.</p>

<p>The IEEE standard floating point types currently supported by D are <span class="d_inlinecode donthyphenate notranslate">float</span> and <span class="d_inlinecode donthyphenate notranslate">double</span>. Additionally, D supports the <span class="d_inlinecode donthyphenate notranslate">real</span> type, which is either 'IEEE 80-bit extended' if supported by the CPU; otherwise, it is the same as <span class="d_inlinecode donthyphenate notranslate">double</span>. In the future, the new types from 754-2008 will be added: <span class="d_inlinecode donthyphenate notranslate">quadruple</span>, <span class="d_inlinecode donthyphenate notranslate">decimal64</span>, and <span class="d_inlinecode donthyphenate notranslate">decimal128</span>.</p>

<p>The characteristics of these types are easily accessible in the language via <i>properties</i>. For example, <span class="d_inlinecode donthyphenate notranslate">float.max</span> is the maximum value which can be stored in a float; <span class="d_inlinecode donthyphenate notranslate">float.mant_dig</span> is the number of digits (bits) stored in the mantissa.</p>

<p>To make sense of mathematics in D, it's necessary to have a basic understanding of IEEE floating-point arithmetic. Fundamentally, it is a mapping of the infinitely many real numbers onto a small number of bytes. Only 4000 million distinct numbers are representable as an IEEE 32-bit float. Even with such a pathetically small representation space, IEEE floating point arithmetic does a remarkably good job of maintaining the illusion that mathematical real numbers are being used; but it's important to understand when the illusion breaks down.</p>

<p>Most problems arise from the distribution of these representable numbers. The IEEE number line is quite different to the mathematical number line.</p>

<pre class="d_code notranslate">
     +     +-----------+------------+    ..   +    ..    +----------+----------+     +       #
-infinity -<span class="d_keyword">float</span>.max  -1  -<span class="d_keyword">float</span>.min_normal   0   <span class="d_keyword">float</span>.min_normal  1  <span class="d_keyword">float</span>.max infinity  NaN

</pre>

<p>Notice that half of the IEEE number line lies between -1 and +1. There are 1000 million representable floats between 0 and 0.5, but only 8 million between 0.5 and 1. This has important implications for accuracy: the effective precision is incredibly high near zero. Several examples will be presented where numbers in the range -1 to +1 are treated seperately to take advantage of this.</p>

<p>Notice also the special numbers: &plusmn;&infin;; the so-called "subnormals" between &plusmn;float.min_normal and 0, which are represented at reduced precision; the fact that there are TWO zeros, +0 and -0, and finally "NaN"("Not-a-Number"), the nonsense value, which caused so much grief in Listing 1.</p>

<p>Why does NaN exist? It serves a valuable role: it <i>eradicates undefined behaviour</i> from floating-point arithmetic. This makes floating-point completely predictable. Unlike the <span class="d_inlinecode donthyphenate notranslate">int</span> type, where 3/0 invokes a hardware division by zero trap handler, possibly ending your program, the floating-point division 3.0/0.0 results in &infin;. Numeric overflow (eg, <span class="d_inlinecode donthyphenate notranslate">real.max*2</span>) also creates &infin;. Depending on the application, &infin; may be a perfectly valid result; more typically, it indicates an error. Nonsensical operations, such as <span class="d_inlinecode donthyphenate notranslate">0.0 / 0.0</span>, result in NaN; but <i>your program does not lose control</i>. At first glance, infinity and NaN may appear unnecessary -- why not just make it an error, just as in the integer case? After all, it is easy to avoid division by zero, simply by checking for a zero denominator before every division. The real difficulty comes from overflow: it is extremely difficult to determine in advance whether an overflow will occur in a multiplication.</p>

<p>Subnormals are necessary to prevent certain anomalies, and preserve important relationships such as: "x - y == 0 if and only if x == y".</p>

<p>Since &infin; can be produced by overflow, both +&infin; and -&infin; are required. Both +0 and -0 are required in order to preserve identities such as: if <span class="d_inlinecode donthyphenate notranslate">x&gt;0</span>, then <span class="d_inlinecode donthyphenate notranslate">1/(1/x) &gt; 0</span>. In almost all other cases, however, there is no difference between +0 and -0.</p>

<p>It's worth noting that these &lsquo;special values&rsquo; are usually not very efficient. On x86 machines, for example, a multiplication involving a NaN, an infinity, or a subnormal can be twenty to fifty times slower than an operation on normal numbers. If your numerical code is unexpectedly slow, it's possible that you are inadvertently creating many of these special values. Enabling floating-point exception trapping, described later, is a quick way to confirm this.</p>

<p>One of the biggest factor obscuring what the machine is doing is in the conversion between binary and decimal. You can eliminate this by using the <span class="d_inlinecode donthyphenate notranslate">"%a"</span> format when displaying results. This is an invaluable debugging tool, and an enormously helpful aid when developing floating-point algorithms. The <span class="d_inlinecode donthyphenate notranslate">0x1.23Ap+6</span> hexadecimal floating-point format can also be used in source code for ensuring that your input data is <i>exactly</i> what you intended.</p>

<h2>The Quantized Nature of Floating-Point</h2>

<p>The fact that the possible values are limited gives access to some operations which are not possible on mathematical real numbers. Given a number x,
<span class="d_inlinecode donthyphenate notranslate">nextUp(x)</span> gives the next representable number which is greater than x.
<span class="d_inlinecode donthyphenate notranslate">nextDown(x)</span> gives the next representable number which is less than x.
</p>

<p>Numerical analysts often describe errors in terms of "units in the last place"(ulp), a surprisingly subtle term which is often used rather carelessly. [footnote:
The most formal definition is found in [J.-M. Muller, "On the definition of ulp(x)",INRIA Technical Report 5504 (2005).]: If <span class="d_inlinecode donthyphenate notranslate">x</span> is a real number that lies between two finite consecutive floating-point numbers a and b of type F, without being equal to one of them, then ulp(x)=abs(b-a); otherwise ulp(x) = <span class="d_inlinecode donthyphenate notranslate">x*F.epsilon</span>. Moreover, ulp(NaN) is NaN, and ulp(&plusmn;F.infinity) = &plusmn;<span class="d_inlinecode donthyphenate notranslate">F.max*F.epsilon</span>.]
I prefer a far simpler definition: The difference in ulps between two numbers x and y is is the number of times which you need to call nextUp() or nextDown() to move from x to y. [Footnote: This will not be an integer if either x or y is a real number, rather than a floating point number.]
The D library function <span class="d_inlinecode donthyphenate notranslate">feqrel(x, y)</span> gives the number of bits which are equal between x and y; it is an easy way to check for loss-of-precision problems.
</p>

<p>The quantized nature of floating point has some interesting consequences.</p>

<ul><li>ANY mathematical range [a,b), (a,b], or (a,b) can be converted into a range
or the form [a,b]. (The converse does not apply: there is no (a,b)
equivalent to [-&infin;, &infin;]).</li>
<li>A naive binary chop doesn't work correctly. The fact that there are hundreds or thousands of times as many representable numbers between 0 and 1, as there are between 1 and 2, is problematic for divide-and-conquer algorithms. A naive binary chop would divide the interval [0 .. 2] into [0 .. 1] and [1 .. 2]. Unfortunately, this is not a true binary chop, because the interval [0 .. 1] contains more than 99% of the representable numbers from the original interval!</li>
</ul>

<h2>Condition number</h2>

<p>Using nextUp, it's easy to approximately calculate the condition number.</p>

<pre class="d_code notranslate"><span class="d_keyword">real</span> x = 0x1.1p13L;
<span class="d_keyword">real</span> u = nextUp(x);

<span class="d_keyword">int</span> bitslost = feqrel(x, u) - feqrel(exp(x), exp(u));
</pre>

<p>This shows that at these huge values of x, a one-bit error in x destroys 12 bits of accuracy in exp(x)!
The error has increased by roughly 6000 units in the last place. The condition number is thus 6000 at this value of x.
</p>

<h2>The semantics of float, double, and real</h2>

<p>For the x86 machines which dominate the market, floating point has traditionally been performed on a descendent of the 8087 math coprocessor. These "x87" floating point units were the first to implement IEEE754 arithmetic. The SSE2 instruction set is an alternative for x86-64 processors, but x87 remains the only portable option for floating point 32-bit x86 machines (no 32-bit AMD processors support SSE2).</p>

<p>The x87 is unusual compared to most other floating-point units. It _only_ supports 80-bit operands, henceforth termed "real80". All <span class="d_inlinecode donthyphenate notranslate">double</span> and <span class="d_inlinecode donthyphenate notranslate">float</span> operands are first converted to 80-bit, all arithmetic operations are performed at 80-bit precision, and the results are reduced to 64-bit or 32-bit precision if required. This means that the results can be significantly more accurate than on a machine which supports at most 64 bit operations. However, it also poses challenges for writing portable code.
(Footnote: The x87 allows you to reduce the mantissa length to be the same as '<span class="d_inlinecode donthyphenate notranslate">double</span> or <span class="d_inlinecode donthyphenate notranslate">float</span>, but it retains the real80 exponent, which means different results are obtained with subnormal numbers. To precisely emulate <span class="d_inlinecode donthyphenate notranslate">double</span> arithmetic slows down floating point code by an order of magnitude).
</p>

<p>Apart from the x87 family, the Motorola 68K (but not ColdFire) and Itanium processors are the only ones which support 80-bit floating point.</p>

<p>A similar issue relates to the FMA (fused multiply and accumulate) instruction, which is available on an increasing number of processors, including PowerPC, Itanium, Sparc, and Cell. On such processors, when evaluating expressions such as <span class="d_inlinecode donthyphenate notranslate">x*y + z</span>, the <span class="d_inlinecode donthyphenate notranslate">x*y</span> is performed at twice the normal precison. Some calculations which would otherwise cause a total loss of precision, are instead calculated exactly.
The challenge for a high-level systems programming language is to create an abstraction which provides predictable behaviour on all platforms, but which nonetheless makes good use of the available hardware.
</p>

<p>D's approach to this situation arises from the following observations:</p>

<ol><li>It is extremely costly performance-wise to ensure identical behaviour on all processors. In particular, it is crippling for the x87.</li>
<li>Very many programs will only run on a particular processor. It would be unfortunate to deny the use of more accurate hardware, for the sake of portability which would never be required.</li>
<li>The requirements for portability and for high precision are never required simultaneously. If <span class="d_inlinecode donthyphenate notranslate">double</span> precision is inadequate, increasing the precision on only some processors doesn't help.</li>
<li>The language should not be tied to particular features of specific processors. </li>
</ol>

<p>A key design goal is: it should be possible to write code such that, regardless of the processor which is used, the accuracy is never worse than would be obtained on a system which only supports the <span class="d_inlinecode donthyphenate notranslate">double</span> type.</p>

<p>(Footnote: <span class="d_inlinecode donthyphenate notranslate">real</span> is close to &lsquo;indigenous&rsquo; in the Borneo proposal for the Java programming language[Ref Borneo]).</p>

<p>Consider evaluating <span class="d_inlinecode donthyphenate notranslate">x*y + z*w</span>, where <span class="d_inlinecode donthyphenate notranslate">x, y, z</span> and <span class="d_inlinecode donthyphenate notranslate">w</span> are double.</p>

<ol><li>double r1 = x * y + z * w;</li>
<li>double a  = x * y; double r2 = a + z * w;</li>
<li>real   b  = x * y; double r3 = b + z * w;</li>
</ol>

<p>Note that during optimisation, (2) and (3) may be transformed into (1), but this is implementation-dependent.
Case (2) is particularly problematic, because it introduces an additional rounding.
</p>

<p>On a "simple" CPU, r1==r2==r3. We will call this value r0.
On PowerPC, r2==r3, but r1 may be more accurate than the others, since it enables use of FMA.
On x86, r1==r3, which may be more accurate than r0, though not as much as for the PowerPC case.
r2, however, may be LESS accurate than r0.
</p>

<p>By using <span class="d_inlinecode donthyphenate notranslate">real</span> for intermediate values, we are guaranteed that our results are never worse than for a simple CPU which only supports <span class="d_inlinecode donthyphenate notranslate">double</span>.</p>

<h2>Properties of the Built-in Types</h2>

<p>The fundamental floating-point properties are <span class="d_inlinecode donthyphenate notranslate">epsilon</span>, <span class="d_inlinecode donthyphenate notranslate">min_normal</span> and <span class="d_inlinecode donthyphenate notranslate">max</span>. The six integral properties are simply the log2 or log10 of these three.</p>

<table border="1" cellpadding="4" cellspacing="0">
              <tr><th scope="col">&nbsp;</th> <th scope="col">float</th> <th scope="col">double</th> <th scope="col">real80</th> <th scope="col">quadruple</th> <th scope="col">decimal64</th> <th scope="col">decimal128</th></tr>
<tr><td>epsilon</td> <td>0x1p-23</td> <td>0x1p-52</td> <td>0x1p-63</td> <td>0x1p-112</td> <td>1e-16 (1p-54)</td> <td>1e-34 (1p-113)</td></tr>
<tr><td>[min_normal</td> <td>0x1p-126</td> <td>0x1p-1022</td> <td>0x1p-16382</td> <td>0x1p-16382</td> <td>1e-383</td> <td>1e-6143</td></tr>
<tr><td>..max)</td> <td>0x1p+128</td> <td>0x1p+1024</td> <td>0x1p+16384</td> <td>0x1p+16384</td> <td>1e+385</td> <td>1e+6145</td></tr>
<tr><td colspan="7">binary properties</td></tr>
<tr><td>mant_dig</td> <td>24</td> <td>53</td> <td>64</td> <td>113</td> <td>53</td> <td>112</td></tr>
<tr><td>min_exp</td> <td>-125</td> <td>-1021</td> <td>-16381</td> <td>-16381</td> <td>&nbsp;</td> <td>&nbsp;</td></tr>
<tr><td>max_exp</td> <td>+128</td> <td>+1024</td> <td>+16384</td> <td>+16384</td> <td>&nbsp;</td> <td>&nbsp;</td></tr>
<tr><td colspan="7">decimal properties</td></tr>
<tr><td>dig</td> <td>6</td> <td>15</td> <td>18</td> <td>33</td> <td>16</td> <td>34</td></tr>
<tr><td>min_10_exp</td> <td>-37</td> <td>-307</td> <td>-4932</td> <td>-4932</td> <td>-382</td> <td>-6142</td></tr>
<tr><td>max_10_exp</td> <td>+38</td> <td>+308</td> <td>+4932</td> <td>+4932</td> <td>385</td> <td>+6145</td></tr>
</table>

<p>When writing code which should adapt to different CPUs at compile time, use <span class="d_inlinecode donthyphenate notranslate">static if</span> with the <span class="d_inlinecode donthyphenate notranslate">mant_dig</span> property. For example, <span class="d_inlinecode donthyphenate notranslate">static if (real.mant_dig==64)</span> is true if 80-bit reals are available.
For binary types, the <span class="d_inlinecode donthyphenate notranslate">dig</span> property gives only the <i>minimum</i> number of valid decimal digits. To ensure that that every representable number has a unique decimal representation, two additional digits are required. Similarly, for decimal numbers, <span class="d_inlinecode donthyphenate notranslate">mant_dig</span> is a lower bound on the number of valid binary digits.
</p>

<h2>Useful relations for a floating point type <span class="d_inlinecode donthyphenate notranslate">F</span>, where <span class="d_inlinecode donthyphenate notranslate">x</span> and <span class="d_inlinecode donthyphenate notranslate">y</span> are of type <span class="d_inlinecode donthyphenate notranslate">F</span></h2>

<ul><li>The smallest representable number is <span class="d_inlinecode donthyphenate notranslate">F.min_normal * F.epsilon</span></li>
<li>Any integer between 0 and <span class="d_inlinecode donthyphenate notranslate">(1/F.epsilon)</span> can be stored in F without loss of precision.
  <span class="d_inlinecode donthyphenate notranslate">1/F.epsilon</span> is always a exact power of the base.</li>
<li>If a number <span class="d_inlinecode donthyphenate notranslate">x</span> is subnormal, <span class="d_inlinecode donthyphenate notranslate">x*(1/F.epsilon)</span> is normal, and
  <span class="d_inlinecode donthyphenate notranslate">exponent(x) = exponent(x*(1/F.epsilon)) - (mant_dig-1)</span>.</li>
<li><span class="d_inlinecode donthyphenate notranslate">x&gt;0</span> if and only if <span class="d_inlinecode donthyphenate notranslate">1/(1/x) &gt; 0</span>; <span class="d_inlinecode donthyphenate notranslate">x&lt;0</span> if and only if <span class="d_inlinecode donthyphenate notranslate">1/(1/x) &lt; 0</span>.</li>
<li>If <span class="d_inlinecode donthyphenate notranslate">x-y==0</span>, then <span class="d_inlinecode donthyphenate notranslate">x==y  &amp;&amp; isFinite(x) &amp;&amp; isFinite(y)</span>. Note that if <span class="d_inlinecode donthyphenate notranslate">x==y==infinity</span>, then <span class="d_inlinecode donthyphenate notranslate">isNaN(x-y)</span>.</li>
<li><span class="d_inlinecode donthyphenate notranslate">F.max * F.min_normal = 4.0</span> for binary types, <span class="d_inlinecode donthyphenate notranslate">10.0</span> for decimal types.</li>
</ul>

<h3> Addition and subtraction</h3>

<ul><li>Some loss of precision occurs with x&plusmn;y if exponent(x)!=exponent(y). The number of digits of precision which are lost is abs(exponent(x)-exponent(y)).</li>
<li>x&plusmn;y has total loss of precision, if and only if
   (1)  <span class="d_inlinecode donthyphenate notranslate">abs(x * F.epsilon) &gt; abs(y)</span>, in which case x+y == x, x-y == x
or (2)  <span class="d_inlinecode donthyphenate notranslate">abs(y * F.epsilon) &gt; abs(x)</span>, in which case x+y == y, x-y == -y</li>
<li>Addition is commutative: <span class="d_inlinecode donthyphenate notranslate">a + b == b + a</span>.</li>
<li>Subtraction is not quite commutative: <span class="d_inlinecode donthyphenate notranslate">a - b == -(b - a)</span>, but produce +0 and -0 if a==b.</li>
<li>Addition is not associative at all.</li>
</ul>

<h3>Multiplication and division</h3>

<ul><li>Multiplication and division are <i>always</i> at risk of overflow or underflow.
  For any <span class="d_inlinecode donthyphenate notranslate">abs(x) &gt; F.epsilon</span>, there is at least one finite <span class="d_inlinecode donthyphenate notranslate">y</span> such that <span class="d_inlinecode donthyphenate notranslate">x/y</span> will overflow to &infin;.
  For any <span class="d_inlinecode donthyphenate notranslate">abs(x) &lt; F.epsilon</span>, there is at least one finite <span class="d_inlinecode donthyphenate notranslate">y</span> such that <span class="d_inlinecode donthyphenate notranslate">x/y</span> will underflow to zero.
  For any <span class="d_inlinecode donthyphenate notranslate">abs(x) &gt; 1</span>, there is at least one finite <span class="d_inlinecode donthyphenate notranslate">y</span> such that <span class="d_inlinecode donthyphenate notranslate">x*y</span> will overflow to &infin;.
  For any <span class="d_inlinecode donthyphenate notranslate">abs(x) &lt; 1</span>, there is at least one finite <span class="d_inlinecode donthyphenate notranslate">y</span> such that <span class="d_inlinecode donthyphenate notranslate">x*y</span> will underflow to zero.
</li>
<li><span class="d_inlinecode donthyphenate notranslate">x*x</span> will overflow if <span class="d_inlinecode donthyphenate notranslate">abs(x)&gt;sqrt(F.max)</span>, and underflow to zero if <span class="d_inlinecode donthyphenate notranslate">abs(x) &lt; sqrt(F.min_normal*F.epsilon)</span>  </li>
<li>Multiplication is commutative. <span class="d_inlinecode donthyphenate notranslate">a * b == b * a</span></li>.
<li>Multiplication is not associative in general: <span class="d_inlinecode donthyphenate notranslate">a*(b*c) != (a*b)*c</span>, because (1) there is a risk of overflow or underflow and (2) <span class="d_inlinecode donthyphenate notranslate">b*c</span> may be an exact calculation, so that <span class="d_inlinecode donthyphenate notranslate">a*(b*c)</span> contains only one round-off error, whereas <span class="d_inlinecode donthyphenate notranslate">(a*b)*c</span> contains two. The roundoff errors may therefore accumulate at the rate of just under 1 ulp per multiplication.</li>
<li>However, a limited form of associativity is possible if the type used for intermediate results is larger than any of the operands (which happens on x87 and Itanium machines). If <span class="d_inlinecode donthyphenate notranslate">R</span> is the intermediate type, and <span class="d_inlinecode donthyphenate notranslate">F</span> is the type being multiplied, up to <span class="d_inlinecode donthyphenate notranslate">min(R.max_exp/F.max_exp, R.epsilon/F.epsilon)</span> values of type <span class="d_inlinecode donthyphenate notranslate">F</span> can be multiplied together in any order without influencing the result. For example, if <span class="d_inlinecode donthyphenate notranslate">R</span> is <span class="d_inlinecode donthyphenate notranslate">double</span>, multiplication of 8 floats <span class="d_inlinecode donthyphenate notranslate">f1*f2*f3*f4*f5*f6*f7*f8</span> is completely associative. On x87, 130 floats can be safely multiplied together in any order, and 16 doubles can similarly be multiplied together safely.
Strict distributivity does not hold even under these circumstances, as it may destroy the sign of -0.</li>
<li>The distributive law almost never holds. For example, <span class="d_inlinecode donthyphenate notranslate">4*x + 6*x != 10*x</span> if <span class="d_inlinecode donthyphenate notranslate">x==nextDown(1.5)</span>. <span class="d_inlinecode donthyphenate notranslate">a*x + b*x == (a+b)*x</span> for all <span class="d_inlinecode donthyphenate notranslate">x</span> only if the operations <span class="d_inlinecode donthyphenate notranslate">a*x, b*x</span>, and <span class="d_inlinecode donthyphenate notranslate">(a+b)</span> are all exact operations, which is true only if <span class="d_inlinecode donthyphenate notranslate">a</span> and <span class="d_inlinecode donthyphenate notranslate">b</span> are exact powers of 2. Even then, if <span class="d_inlinecode donthyphenate notranslate">a==-b</span> and <span class="d_inlinecode donthyphenate notranslate">x==-0</span>, then <span class="d_inlinecode donthyphenate notranslate">a*x+b*x==0.0, (a+b)*x==-0.0</span>.</li>
<li>Performing a division by multiplication by the reciprocal returns a result which (in round-to-nearest mode) is at most 1.5 ulps from the correctly rounded result. For almost any denominator, the rounding is incorrect (&gt;0.5ulps) for 27% of numerators. [Ref: N. Brisebarre, J-M Muller, and S.K. Raina, "Accelerating Correctly Rounded Floating-Point Division when the Divisor Is Known in Advance", IEEE Trans. on Computers, Vol 53, pp 1069-1072 (2004)].</li>
</ul>


<h3> Powers and logarithms</h3>

<ul><li><span class="d_inlinecode donthyphenate notranslate">F.mant_dig = -log2(F.epsilon)</span> for binary types;</li>
<li> <span class="d_inlinecode donthyphenate notranslate">F.dig = -log10(F.epsilon)</span> for decimal types.</li>
<li><span class="d_inlinecode donthyphenate notranslate">F.max =  exp2(F.max_exp*(1-F.epsilon))</span> for binary types;</li>
<li><span class="d_inlinecode donthyphenate notranslate">F.max = exp10(F.max_10_exp*(1-F.epsilon))</span> for decimal types.</li>
<li>For any positive finite <span class="d_inlinecode donthyphenate notranslate">x</span>, <span class="d_inlinecode donthyphenate notranslate">F.min_exp - F.mant_dig &lt;= log2(x) &lt; F.max_exp</span> for binary types,
                             <span class="d_inlinecode donthyphenate notranslate">F.min_10_exp - F.dig &lt;= log10(x) &lt; F.max_10_exp</span>  for decimal types</li>
<li><span class="d_inlinecode donthyphenate notranslate">exp2(x) == 0</span> if <span class="d_inlinecode donthyphenate notranslate">x &lt; F.min_exp - F.mant_dig</span>, <span class="d_inlinecode donthyphenate notranslate">exp2(x) == infinity</span> if <span class="d_inlinecode donthyphenate notranslate">x &gt;= F.max_exp</span></li>
</ul>

<h2>NaN payloads</h2>

<p>According to the IEEE 754 standard, a &lsquo;payload&rsquo; can be stored in the mantissa of a NaN. This payload can contain information about how or why it was generated. Historically, almost no programming languages have ever made use of this potentially powerful feature. In D, this payload consists of a positive integer.</p>

<ul><li><span class="d_inlinecode donthyphenate notranslate">real NaN(ulong payload)</span> -- create a NaN with a "payload", where the payload is a <span class="d_inlinecode donthyphenate notranslate">ulong</span>.</li>
<li><span class="d_inlinecode donthyphenate notranslate">ulong getNaNPayload(real x)</span> -- returns the integer payload. Note that if narrowing conversions have occured, the high-order bits may have changed.</li>
</ul>

<p><i>Never</i> store a pointer as an integer payload inside a NaN. The garbage collector will not be able to find it!</p>

<h2>The IEEE Rounding Modes</h2>

<p>The rounding mode is controlled within a scope. Rounding mode will be restored to its previous state at the end of that scope.
Four rounding modes can be set. The default mode, <i>Round to nearest</i>, is the most statistically accurate, but the least intuitive. In the event of tie, the result is rounded to an even number.
</p>

<table border="1" cellpadding="4" cellspacing="0">
              <tr><th scope="col">Rounding mode</th> <th scope="col">rndint(4.5)</th> <th scope="col">rndint(5.5)</th> <th scope="col">rndint(-4.5)</th> <th scope="col">Notes</th></tr>
<tr><td>Round to nearest</td> <td>4</td> <td>6</td> <td>-4</td> <td>Ties round to an even number</td></tr>
<tr><td>Round down</td> <td>4</td> <td>5</td> <td>-5</td> <td>&nbsp;</td></tr>
<tr><td>Round up</td> <td>5</td> <td>6</td> <td>-4</td> <td>&nbsp;</td></tr>
<tr><td>Round to zero</td> <td>4</td> <td>5</td> <td>-4</td> <td>&nbsp;</td></tr>
</table>

<p>There are very few reasons for changing the rounding mode.
The round-up and round-down modes were created specifically to allow fast implementations of interval arithmetic; they are crucial to certain libraries, but rarely used elsewhere.
The round-to-zero mode is used for casting floating-point numbers to integers. Since mode switching is slow, especially on Intel machines, it may be useful to switch to round-to-zero mode, in order to exactly duplicate the behaviour of <span class="d_inlinecode donthyphenate notranslate">cast(int)</span> in an inner loop.
</p>

<p>The only other commonly cited reason for changing the rounding mode is as a simple check for numerical stability: if the calculation produces wildly different results when the rounding mode is changed, it's a clear sign that it is suffering from round-off errors. </p>

<h2>The IEEE Exception Status Flags</h2>

<p>All IEEE-compiliant processors include special status bits that indicate when "weird" things have happened that programs might want to know about. For example, <span class="d_inlinecode donthyphenate notranslate">ieeeFlags.divideByZero</span> tells if any infinities have been created by dividing by zero. They are 'sticky' bits: once they have been set, they remain set until explicitly cleared. By only checking this once at the end of a calculation, it may be possible to avoid comparing thousands of comparisions that are almost never going to fail.</p>

<p>Here's a list of the weird things that can be detected:</p>

<dl><dt>invalid</dt> <dd>This is set if any NaN's have been generated. This can happen with &infin; - &infin;, &infin; * 0, 0 * &infin;, 0/0, &infin;/&infin;, &infin;%&infin;, or <span class="d_inlinecode donthyphenate notranslate">x%0</span>, for any number <span class="d_inlinecode donthyphenate notranslate">x</span>. Several other operations, such as sqrt(-1), can also generate a NaN. The <i>invalid</i> condition is also set when a 'signalling NaN' is accessed, indicating use of an uninitialized variable. This almost always indicates a programming error.</dd>

<dt>overflow</dt> <dd>Set if &infin; was generated by adding or multiplying two numbers that were so large that the sum was greater than <span class="d_inlinecode donthyphenate notranslate">real.max</span>. This almost always indicates that the result is incorrect; and corrective action needs to be taken.</dd>

<dt>divisionByZero</dt> <dd>Set if &plusmn;&infin; was generated by dividing by zero. This usually indicates a programming error, but not always; some types of calculations return correct results even when division by zero occurs.
(For example, <span class="d_inlinecode donthyphenate notranslate">1/(1+ 1/x) == 0</span> if <span class="d_inlinecode donthyphenate notranslate">x == 0</span>). Note that division by a tiny, almost-zero number also produces an infinite result, but sets the overflow flag rather than the divisionByZero flag.
</dd>

<dt>underflow</dt> <dd>This happens if two numbers are subtracted or divided and are so tiny that the result lost precision because it was subnormal. Extreme underflow produces a zero result. Underflow almost never creates problems, and can usually be ignored.</dd>

<dt>inexact</dt> <dd>This indicates that rounding has occurred. Almost all floating point operations set this flag! It was apparently included in the hardware to support some arcane tricks used in the pioneering days of numerical analysis. It can always be ignored.</dd>
</dl>

<p>Floating-point traps can be enabled for any of the categories listed above. When enabled, a hardware exception will be generated.
This can be an invaluable debugging aid.
A more advanced usage, not yet supported on any platform(!) is to provide a nested function to be used as a hardware exception handler. This is most useful for the overflow and underflow exceptions.
</p>

<h2>Floating point and &lsquo;pure nothrow&rsquo;</h2>

<p>Every floating point operation, even the most trivial, is affected by the floating-point rounding state, and writes to the sticky flags. The status flags and control state are thus 'hidden variables', potentially affecting every <span class="d_inlinecode donthyphenate notranslate">pure</span> function; and if the floating point traps are enabled, any floating point operation can generate a hardware exception.
D provides a facility for the floating-point control mode and exception flags to be usable in limited circumstances even when <span class="d_inlinecode donthyphenate notranslate">pure</span> and <span class="d_inlinecode donthyphenate notranslate">nothrow</span> functions are called.
</p>

<p>[TODO: I've made two proposals, but I haven't persauded Walter yet!].</p>

<h2>Conclusion</h2>

<p>Although D is a general-purpose programming language and supports many high-level concepts, it gives direct and convenient access to almost all features of modern floating-point hardware. This makes it an excellent language for development of robust, high-performance numerical code. It is also a language which encourages a deep understanding of the machine, making it fertile ground for innovation and for developing new algorithms.</p>



<h2>References and Further Reading</h2>

<ol><li><a href="http://docs.sun.com/source/806-3568/ncg_goldberg.html">"What Every Computer Scientist Should Know About Floating-Point Arithmetic"</a>
</li>
<li><a href="http://www.cs.berkeley.edu/~wkahan/ieee754status/754story.html">"An Interview with the Old Man of Floating-Point: Reminiscences elicited from William Kahan by Charles Severance"</a>
</li>
<li>N. Brisebarre, J-M Muller, and S.K. Raina, "Accelerating Correctly Rounded Floating-Point Division when the Divisor Is Known in Advance", IEEE Trans. on Computers, Vol 53, pp 1069-1072 (2004).
</li>
<li><a href="http://www.sonic.net/~jddarcy/Borneo/">"The Borneo language"</a>
</li>
</ol>




        <div class="smallprint" id="copyright">Copyright &copy; 1999-2017 by the <a href="foundation.html">D Language Foundation</a> | Page generated by
<a href="spec/ddoc.html">Ddoc</a> on (no date time)</div>
    </div>
</div>

    <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
    <script type="text/javascript">window.jQuery || document.write('\x3Cscript src="js/jquery-1.7.2.min.js">\x3C/script>');</script>
    <script type="text/javascript" src="js/dlang.js"></script>
    
    <script type="text/javascript" src="js/codemirror-compressed.js"></script>
    <script type="text/javascript" src="js/run.js"></script>


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
</body>
</html>
